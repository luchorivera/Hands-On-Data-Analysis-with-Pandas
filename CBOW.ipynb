{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "CBOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luchorivera/Hands-On-Data-Analysis-with-Pandas/blob/master/CBOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8WQReaahLqY",
        "colab_type": "text"
      },
      "source": [
        "https://subscription.packtpub.com/book/data/9781789802740/5/ch05lvl1sec20/exploring\n",
        "\n",
        "Hands-On Natural Language Processing with PyTorch 1.x\n",
        "By Thomas Dop\n",
        "July 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGDnO0tSeHXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RugMG3EJeHXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"\"\"How that personage haunted my dreams, I need scarcely tell you. On\n",
        "stormy nights, when the wind shook the four corners of the house and\n",
        "the surf roared along the cove and up the cliffs, I would see him in a\n",
        "thousand forms, and with a thousand diabolical expressions. Now the leg\n",
        "would be cut off at the knee, now at the hip, now he was a monstrous\n",
        "kind of a creature who had never had but the one leg, and that in the\n",
        "middle of his body. To see him leap and run and pursue me over hedge and\n",
        "ditch was the worst of nightmares. And altogether I paid pretty dear for\n",
        "my monthly fourpenny piece, in the shape of these abominable fancies\"\"\"\n",
        "\n",
        "text = text.replace(',','').replace('.','').lower().split()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6Vx0aoveokv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "830f2878-7428-4dd1-9db7-0e8d9de1c0a7"
      },
      "source": [
        "print(text)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['how', 'that', 'personage', 'haunted', 'my', 'dreams', 'i', 'need', 'scarcely', 'tell', 'you', 'on', 'stormy', 'nights', 'when', 'the', 'wind', 'shook', 'the', 'four', 'corners', 'of', 'the', 'house', 'and', 'the', 'surf', 'roared', 'along', 'the', 'cove', 'and', 'up', 'the', 'cliffs', 'i', 'would', 'see', 'him', 'in', 'a', 'thousand', 'forms', 'and', 'with', 'a', 'thousand', 'diabolical', 'expressions', 'now', 'the', 'leg', 'would', 'be', 'cut', 'off', 'at', 'the', 'knee', 'now', 'at', 'the', 'hip', 'now', 'he', 'was', 'a', 'monstrous', 'kind', 'of', 'a', 'creature', 'who', 'had', 'never', 'had', 'but', 'the', 'one', 'leg', 'and', 'that', 'in', 'the', 'middle', 'of', 'his', 'body', 'to', 'see', 'him', 'leap', 'and', 'run', 'and', 'pursue', 'me', 'over', 'hedge', 'and', 'ditch', 'was', 'the', 'worst', 'of', 'nightmares', 'and', 'altogether', 'i', 'paid', 'pretty', 'dear', 'for', 'my', 'monthly', 'fourpenny', 'piece', 'in', 'the', 'shape', 'of', 'these', 'abominable', 'fancies']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iG2-opGAeHXz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7aef6751-04ac-4c13-e29a-63da7dac118c"
      },
      "source": [
        "corpus = set(text)\n",
        "corpus_length = len(corpus)\n",
        "\n",
        "word_dict = {}\n",
        "inverse_word_dict = {}\n",
        "\n",
        "for i, word in enumerate(corpus):\n",
        "    word_dict[word] = i\n",
        "    inverse_word_dict[i] = word\n",
        "\n",
        "data = []\n",
        "\n",
        "for i in range(2, len(text) - 2):\n",
        "    sentence = [text[i-2], text[i-1],\n",
        "               text[i+1], text[i+2]]\n",
        "    target = text[i]\n",
        "    data.append((sentence, target))\n",
        "    \n",
        "print(data[3])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(['haunted', 'my', 'i', 'need'], 'dreams')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgGw7m_meHX4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_length = 20\n",
        "\n",
        "class CBoW(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, corpus_length, embedding_dim):\n",
        "        super(CBoW, self).__init__()\n",
        "        \n",
        "        self.embeddings = nn.Embedding(corpus_length, embedding_dim)\n",
        "\n",
        "        self.linear1 = nn.Linear(embedding_dim, 64)\n",
        "        self.linear2 = nn.Linear(64, corpus_length)\n",
        "        \n",
        "        self.activation_function1 = nn.ReLU()\n",
        "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
        "        out = self.linear1(embeds)\n",
        "        out = self.activation_function1(out)\n",
        "        out = self.linear2(out)\n",
        "        out = self.activation_function2(out)\n",
        "        return out\n",
        "\n",
        "    def get_word_emdedding(self, word):\n",
        "        word = torch.LongTensor([word_dict[word]])\n",
        "        return self.embeddings(word).view(1,-1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS66_LtIeHX8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebc92451-1ea7-47b2-c4c6-82a5222795a5"
      },
      "source": [
        "model = CBoW(corpus_length, embedding_length)\n",
        "\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "def make_sentence_vector(sentence, word_dict):\n",
        "    idxs = [word_dict[w] for w in sentence]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "print(make_sentence_vector(['stormy','nights','when','the'], word_dict))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([13, 78, 61, 68])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usbQVKXleHX_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45a1ea85-1a1e-4365-f906-ce22941b725a"
      },
      "source": [
        "for epoch in range(100):\n",
        "    epoch_loss = 0\n",
        "    for sentence, target in data:\n",
        "        model.zero_grad()\n",
        "        sentence_vector = make_sentence_vector(sentence, word_dict)  \n",
        "        log_probs = model(sentence_vector)\n",
        "        loss = loss_function(log_probs, torch.tensor([word_dict[target]], dtype=torch.long))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.data\n",
        "    print('Epoch: '+str(epoch)+', Loss: ' + str(epoch_loss.item()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 543.7525634765625\n",
            "Epoch: 1, Loss: 481.09637451171875\n",
            "Epoch: 2, Loss: 437.6916809082031\n",
            "Epoch: 3, Loss: 399.732177734375\n",
            "Epoch: 4, Loss: 363.3277282714844\n",
            "Epoch: 5, Loss: 326.68975830078125\n",
            "Epoch: 6, Loss: 289.6161804199219\n",
            "Epoch: 7, Loss: 252.344482421875\n",
            "Epoch: 8, Loss: 216.13104248046875\n",
            "Epoch: 9, Loss: 181.6922607421875\n",
            "Epoch: 10, Loss: 149.91403198242188\n",
            "Epoch: 11, Loss: 122.03185272216797\n",
            "Epoch: 12, Loss: 98.26849365234375\n",
            "Epoch: 13, Loss: 78.60071563720703\n",
            "Epoch: 14, Loss: 62.97425079345703\n",
            "Epoch: 15, Loss: 50.74811553955078\n",
            "Epoch: 16, Loss: 41.1762809753418\n",
            "Epoch: 17, Loss: 33.832183837890625\n",
            "Epoch: 18, Loss: 28.221006393432617\n",
            "Epoch: 19, Loss: 23.857149124145508\n",
            "Epoch: 20, Loss: 20.491724014282227\n",
            "Epoch: 21, Loss: 17.829341888427734\n",
            "Epoch: 22, Loss: 15.712153434753418\n",
            "Epoch: 23, Loss: 13.987968444824219\n",
            "Epoch: 24, Loss: 12.581228256225586\n",
            "Epoch: 25, Loss: 11.39668083190918\n",
            "Epoch: 26, Loss: 10.401822090148926\n",
            "Epoch: 27, Loss: 9.558734893798828\n",
            "Epoch: 28, Loss: 8.827138900756836\n",
            "Epoch: 29, Loss: 8.19446086883545\n",
            "Epoch: 30, Loss: 7.6382155418396\n",
            "Epoch: 31, Loss: 7.148861885070801\n",
            "Epoch: 32, Loss: 6.713310241699219\n",
            "Epoch: 33, Loss: 6.326160907745361\n",
            "Epoch: 34, Loss: 5.975589752197266\n",
            "Epoch: 35, Loss: 5.6626973152160645\n",
            "Epoch: 36, Loss: 5.376559257507324\n",
            "Epoch: 37, Loss: 5.116401195526123\n",
            "Epoch: 38, Loss: 4.879809379577637\n",
            "Epoch: 39, Loss: 4.661309242248535\n",
            "Epoch: 40, Loss: 4.461026668548584\n",
            "Epoch: 41, Loss: 4.275954246520996\n",
            "Epoch: 42, Loss: 4.105020999908447\n",
            "Epoch: 43, Loss: 3.946032762527466\n",
            "Epoch: 44, Loss: 3.7983663082122803\n",
            "Epoch: 45, Loss: 3.6608405113220215\n",
            "Epoch: 46, Loss: 3.5318188667297363\n",
            "Epoch: 47, Loss: 3.4113364219665527\n",
            "Epoch: 48, Loss: 3.298362970352173\n",
            "Epoch: 49, Loss: 3.1920130252838135\n",
            "Epoch: 50, Loss: 3.092050790786743\n",
            "Epoch: 51, Loss: 2.9975030422210693\n",
            "Epoch: 52, Loss: 2.908459424972534\n",
            "Epoch: 53, Loss: 2.8240320682525635\n",
            "Epoch: 54, Loss: 2.743973970413208\n",
            "Epoch: 55, Loss: 2.6682395935058594\n",
            "Epoch: 56, Loss: 2.595848798751831\n",
            "Epoch: 57, Loss: 2.5278520584106445\n",
            "Epoch: 58, Loss: 2.4624571800231934\n",
            "Epoch: 59, Loss: 2.4004266262054443\n",
            "Epoch: 60, Loss: 2.3411920070648193\n",
            "Epoch: 61, Loss: 2.2843105792999268\n",
            "Epoch: 62, Loss: 2.230721950531006\n",
            "Epoch: 63, Loss: 2.1787915229797363\n",
            "Epoch: 64, Loss: 2.1293044090270996\n",
            "Epoch: 65, Loss: 2.08172345161438\n",
            "Epoch: 66, Loss: 2.0365190505981445\n",
            "Epoch: 67, Loss: 1.9924854040145874\n",
            "Epoch: 68, Loss: 1.950576663017273\n",
            "Epoch: 69, Loss: 1.9103094339370728\n",
            "Epoch: 70, Loss: 1.871584415435791\n",
            "Epoch: 71, Loss: 1.8341450691223145\n",
            "Epoch: 72, Loss: 1.7979953289031982\n",
            "Epoch: 73, Loss: 1.7635020017623901\n",
            "Epoch: 74, Loss: 1.7299222946166992\n",
            "Epoch: 75, Loss: 1.6975613832473755\n",
            "Epoch: 76, Loss: 1.6664291620254517\n",
            "Epoch: 77, Loss: 1.6362965106964111\n",
            "Epoch: 78, Loss: 1.607126235961914\n",
            "Epoch: 79, Loss: 1.5790207386016846\n",
            "Epoch: 80, Loss: 1.5518065690994263\n",
            "Epoch: 81, Loss: 1.5253007411956787\n",
            "Epoch: 82, Loss: 1.499744176864624\n",
            "Epoch: 83, Loss: 1.4749876260757446\n",
            "Epoch: 84, Loss: 1.4509949684143066\n",
            "Epoch: 85, Loss: 1.427725911140442\n",
            "Epoch: 86, Loss: 1.4051254987716675\n",
            "Epoch: 87, Loss: 1.3830941915512085\n",
            "Epoch: 88, Loss: 1.3618558645248413\n",
            "Epoch: 89, Loss: 1.3411039113998413\n",
            "Epoch: 90, Loss: 1.3209782838821411\n",
            "Epoch: 91, Loss: 1.3014602661132812\n",
            "Epoch: 92, Loss: 1.2823776006698608\n",
            "Epoch: 93, Loss: 1.2639192342758179\n",
            "Epoch: 94, Loss: 1.245862364768982\n",
            "Epoch: 95, Loss: 1.2283260822296143\n",
            "Epoch: 96, Loss: 1.2112172842025757\n",
            "Epoch: 97, Loss: 1.1946085691452026\n",
            "Epoch: 98, Loss: 1.1783539056777954\n",
            "Epoch: 99, Loss: 1.1625150442123413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG0RY7oqeHYD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0a27e5f6-4364-47a7-df6b-879f5ddf7567"
      },
      "source": [
        "def get_predicted_result(input, inverse_word_dict):\n",
        "    index = np.argmax(input)\n",
        "    return inverse_word_dict[index]\n",
        "\n",
        "def predict_sentence(sentence):\n",
        "    sentence_split = sentence.replace('.','').lower().split()\n",
        "    sentence_vector = make_sentence_vector(sentence_split, word_dict)\n",
        "    prediction_array = model(sentence_vector).data.numpy()\n",
        "    print('Preceding Words: {}\\n'.format(sentence_split[:2]))\n",
        "    print('Predicted Word: {}\\n'.format(get_predicted_result(prediction_array[0], inverse_word_dict)))\n",
        "    print('Following Words: {}\\n'.format(sentence_split[2:]))\n",
        "\n",
        "predict_sentence('to see leap and')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preceding Words: ['to', 'see']\n",
            "\n",
            "Predicted Word: him\n",
            "\n",
            "Following Words: ['leap', 'and']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKTLM88reHYI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c1dc3b16-3f62-42a7-be5c-8bbf761ae3f3"
      },
      "source": [
        "print(model.get_word_emdedding('leap'))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0706, -0.2392,  0.3957,  0.5724, -0.4644, -0.0312, -1.9006,  0.6281,\n",
            "         -1.5343, -0.6428, -0.6508,  0.2963, -0.9421, -0.0606,  0.1141, -0.0499,\n",
            "         -1.0135, -0.6442, -1.4822, -0.0357]], grad_fn=<ViewBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKksgctCeHYM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5614a155-2939-428b-c66d-41651d06a39c"
      },
      "source": [
        "predict_sentence('a monstrous of a')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preceding Words: ['a', 'monstrous']\n",
            "\n",
            "Predicted Word: kind\n",
            "\n",
            "Following Words: ['of', 'a']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJD-Vs5weHYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}